---
title: "How to build a webscraper in R for retrieving restaurant information form Iens?"
author: "Youssef El Bouhassani, y.elbouhassani@gmail.com"
date: "12 december 2017"
output: html_document
---

## Context
Webscraping is handig om informatie uit websites te halen. In deze tutorial gaan we informatie uit <www.iens.nl> halen.

## Approach
we gaan het volgend proces volgen
1. Maak een lijst van urls van individuele resultaten paginas
2. Uit de lijst van resultaten haal de urls naar individuele restaurants
3. Uit de individuele paginas van resutaurants haal de naam en rating (en eventueel andere info.)

## Build the scraper
### Step 0: Getting things ready
We hebben twee dingen nodig
1. De SelectorGadget (installeren als add on op de browser)
2. R libraries

```{r, echo=TRUE,message=FALSE,warning=FALSE}
library(rvest)
library(dplyr)
```

De volgende functies uit `rvest` hebben we nodig
1. `read_html()` deze functie haal de html code binnen gegeven een url. 
2. `html_node()` deze functie haalt de html code binnen die bij een specifieke `css` tag hoort
3. `html_text()` deze functie geeft de leesbare text uit een html code
4. `html_attr()` deze functie geeft de attributen die achter een html node zitten. Bijvoorbeeld de functie `html_attr("href")`

`url %>% read_html() %>% html_nodes("NameTag") %>% html_text()` 

### Step 1. Get the website url
definieer een url die we gaan scrapen
```{r, echo=TRUE,message=FALSE,warning=FALSE}
url <- "https://www.iens.nl/restaurant+amsterdam"
```

### Step 2. Get the links to individual pages

```{r, echo=TRUE,message=FALSE,warning=FALSE}
lastpage <- url %>% read_html() %>% html_nodes("#pagination_results a") %>% html_text()
lastpage <- as.numeric(lastpage[length(lastpage)-1])

urllist <- paste("https://www.iens.nl/restaurant+amsterdam?page=",1:lastpage,sep="")
```

We hebben nu een lijst van alle paginas met resultaten. Uit deze paginas willen de urls naar de individeule restraurants. 

```{r, echo=TRUE,message=FALSE,warning=FALSE}
resurl <- lapply(urllist[1:3],function(x){x %>% 
    read_html() %>% 
    html_nodes(".resultItem-name a") %>% 
    html_attr("href") %>%
    paste("https://www.iens.nl",.,sep="")}) %>% 
  unlist()
```

### Step 3. Get information about restaurants
Uit de individuele restraurantpaginas haal de naam en de rating binnen. 

Voor het vinden van de gemiddelde rating is het belangrijk om alleen de rating bij de naam te selecteren. Bij het gebruiken van de SelectorGadget om de ratings te selecteren, worden ook individuele ratings meegenomen. Je moet dus expliciet aangeven dat je het gemiddelde wil hebben, door andere rating weg te klikken. 
```{r, echo=TRUE,message=FALSE,warning=FALSE}
df <- data.frame(naam = character(0),rating = numeric(0))

for(i in 1:5) {
  # Read html for individual restaurants
  res_html <- resurl[i] %>% read_html()
  
  # get the name
  naam <- res_html %>% 
    html_nodes(".restaurantSummary-name") %>% 
    html_text() %>%
    ifelse(is.null(.),NA,.)
  
  # get the rating
  rating <- res_html %>% 
    html_nodes("#restaurantAvgRating .rating-ratingValue") %>% 
    html_text() %>% gsub(",",".",.) %>%
    as.numeric() %>%
    ifelse(is.null(.),NA,.)
  
  # Add new rows to the old dataframe
  df <- rbind(df,data.frame(naam,rating))
}

write.csv(df,"RestaurantRating.csv",row.names = FALSE)
```

